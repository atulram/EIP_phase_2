{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_S6E3",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3YmPFUSvty_",
        "colab_type": "text"
      },
      "source": [
        "## Importing the classes and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "029KTsAfIvh4",
        "colab_type": "code",
        "outputId": "0689a6e0-2c66-46e3-f4be-4cb475e9caeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import sys\n",
        "import string\n",
        "import pprint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqpxRIOGv7p4",
        "colab_type": "text"
      },
      "source": [
        "## Loading the text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6daab6b9-e943-4f4c-fc3b-9d9a2dedbab6",
        "id": "NEO3osfwQ_7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "!git clone https://github.com/atulram/EIP_phase_2.git\n",
        "  \n",
        "filename = \"/content/EIP_phase_2/session6/wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EIP_phase_2'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 15 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTEjtuhQFOub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing the texts from the begining and end which are not the part of the book\n",
        "\n",
        "begin, rest = raw_text.split(\"*** START OF THIS PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND ***\".lower())\n",
        "raw_text, end = rest.split(\"              the end\\n\\n\\n\\n\\n\\nEnd of Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll\".lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_pstRAMG8G_",
        "colab_type": "code",
        "outputId": "e126d6ca-8bf5-4e3c-9e0a-3461b613dbba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(sorted(list(set(raw_text))))\n",
        "\n",
        "print(\"Before Removing Punctuation\")\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Removing Punctuation\n",
            "Total Characters:  144420\n",
            "Total Vocab:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kevl8OfwEG2I",
        "colab_type": "text"
      },
      "source": [
        "## Removing Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT9dItUyD_fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using maketrans() to construct translate table\n",
        "\n",
        "table = str.maketrans(\"\",\"\", string.punctuation)\n",
        "raw_text = raw_text.translate(table) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_RFxvBrQvGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i+1) for i, c in enumerate(chars)) ## index starting from 1 so as to facilitate padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KRHg0B8TKwa",
        "colab_type": "code",
        "outputId": "464f4a67-c24f-4fd6-9f80-b930ca3989a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 1,\n",
              " ' ': 2,\n",
              " '0': 3,\n",
              " '3': 4,\n",
              " 'a': 5,\n",
              " 'b': 6,\n",
              " 'c': 7,\n",
              " 'd': 8,\n",
              " 'e': 9,\n",
              " 'f': 10,\n",
              " 'g': 11,\n",
              " 'h': 12,\n",
              " 'i': 13,\n",
              " 'j': 14,\n",
              " 'k': 15,\n",
              " 'l': 16,\n",
              " 'm': 17,\n",
              " 'n': 18,\n",
              " 'o': 19,\n",
              " 'p': 20,\n",
              " 'q': 21,\n",
              " 'r': 22,\n",
              " 's': 23,\n",
              " 't': 24,\n",
              " 'u': 25,\n",
              " 'v': 26,\n",
              " 'w': 27,\n",
              " 'x': 28,\n",
              " 'y': 29,\n",
              " 'z': 30}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXofbQf_kvG1",
        "colab_type": "code",
        "outputId": "78fba1e2-006c-4729-aac4-16c7e940cfd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print(\"After Removing Punctuation\")\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After Removing Punctuation\n",
            "Total Characters:  136100\n",
            "Total Vocab:  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU5JgUiLwCbF",
        "colab_type": "text"
      },
      "source": [
        "## Define the training data for the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBheFK77mfkO",
        "colab_type": "code",
        "outputId": "3a64837e-28a4-4418-ef5b-223934467d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "raw_text = ' '+raw_text\n",
        "\n",
        "for i in range(1, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  \n",
        "  ##Checking for incomplete words in the beginning of the sequence\n",
        "  if raw_text[i-1]!=' ':\n",
        "    \n",
        "    ## removing the random letters of the left most word. This will be adjusted by pre-sequence padding\n",
        "    seq_in = seq_in[seq_in.find(' ')+1:]\n",
        "  \n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  135999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfFnUj8O3ihT",
        "colab_type": "text"
      },
      "source": [
        "## Making a padded sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wo2-8Nv0x7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre pad sequence\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "paddedX = pad_sequences(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAeAjPm81S9e",
        "colab_type": "code",
        "outputId": "23c66631-b959-407c-94ba-c40ca6fd1d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "print(paddedX)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  1  1 ...  7 12  5]\n",
            " [ 0  0  0 ... 12  5 20]\n",
            " [ 0  0  0 ...  5 20 24]\n",
            " ...\n",
            " [ 0  0  5 ...  2  8  5]\n",
            " [ 0  5 18 ...  8  5 29]\n",
            " [ 5 18  8 ...  5 29 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjNK4vAVvcJk",
        "colab_type": "text"
      },
      "source": [
        "## Transform data to use it with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BazFI3G8udSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(paddedX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBMGvDf81lQz",
        "colab_type": "code",
        "outputId": "37271bd1-1edd-42f7-baa0-916822c8de2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135999, 100, 1)\n",
            "(135999, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q44iwNLJzcLG",
        "colab_type": "text"
      },
      "source": [
        "## Defining the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uu0Ack6xMXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "7d339a62-8e23-4f3c-87ae-ae71de204061"
      },
      "source": [
        "# define the LSTM model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dropout(0.1)) ## Adding dropout to the input layer\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 09:49:29.590418 140480920938368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 09:49:29.636764 140480920938368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 09:49:29.643331 140480920938368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 09:49:30.064712 140480920938368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0727 09:49:30.078297 140480920938368 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0727 09:49:30.441211 140480920938368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 09:49:30.470565 140480920938368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgo4DRuCzpYq",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNMVb8W-ztEw",
        "colab_type": "code",
        "outputId": "38aae5b3-cf62-4768-918e-806441429191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUD5MPWWzh0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"/content/drive/My Drive/EIP/LSTM_weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9zw2yj4b18U",
        "colab_type": "code",
        "outputId": "c5278951-5c7d-4ed1-86cb-29ecb89368f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=50, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 13:19:23.516954 140218529822592 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 13:19:23.521786 140218529822592 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0726 13:19:23.533238 140218529822592 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0726 13:19:23.550444 140218529822592 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 13:19:24.243724 140218529822592 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0726 13:19:24.391890 140218529822592 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "135999/135999 [==============================] - 301s 2ms/step - loss: 2.7913\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.79132, saving model to /content/drive/My Drive/EIP/LSTM_weights-01-2.7913.hdf5\n",
            "Epoch 2/50\n",
            "135999/135999 [==============================] - 288s 2ms/step - loss: 2.5034\n",
            "\n",
            "Epoch 00002: loss improved from 2.79132 to 2.50344, saving model to /content/drive/My Drive/EIP/LSTM_weights-02-2.5034.hdf5\n",
            "Epoch 3/50\n",
            "135999/135999 [==============================] - 286s 2ms/step - loss: 2.2676\n",
            "\n",
            "Epoch 00003: loss improved from 2.50344 to 2.26765, saving model to /content/drive/My Drive/EIP/LSTM_weights-03-2.2676.hdf5\n",
            "Epoch 4/50\n",
            "135999/135999 [==============================] - 279s 2ms/step - loss: 2.1396\n",
            "\n",
            "Epoch 00004: loss improved from 2.26765 to 2.13962, saving model to /content/drive/My Drive/EIP/LSTM_weights-04-2.1396.hdf5\n",
            "Epoch 5/50\n",
            "135999/135999 [==============================] - 278s 2ms/step - loss: 2.0579\n",
            "\n",
            "Epoch 00005: loss improved from 2.13962 to 2.05790, saving model to /content/drive/My Drive/EIP/LSTM_weights-05-2.0579.hdf5\n",
            "Epoch 6/50\n",
            "135999/135999 [==============================] - 282s 2ms/step - loss: 1.9927\n",
            "\n",
            "Epoch 00006: loss improved from 2.05790 to 1.99267, saving model to /content/drive/My Drive/EIP/LSTM_weights-06-1.9927.hdf5\n",
            "Epoch 7/50\n",
            "135999/135999 [==============================] - 287s 2ms/step - loss: 1.9433\n",
            "\n",
            "Epoch 00007: loss improved from 1.99267 to 1.94333, saving model to /content/drive/My Drive/EIP/LSTM_weights-07-1.9433.hdf5\n",
            "Epoch 8/50\n",
            "135999/135999 [==============================] - 280s 2ms/step - loss: 1.9017\n",
            "\n",
            "Epoch 00008: loss improved from 1.94333 to 1.90167, saving model to /content/drive/My Drive/EIP/LSTM_weights-08-1.9017.hdf5\n",
            "Epoch 9/50\n",
            "135999/135999 [==============================] - 277s 2ms/step - loss: 1.8669\n",
            "\n",
            "Epoch 00009: loss improved from 1.90167 to 1.86694, saving model to /content/drive/My Drive/EIP/LSTM_weights-09-1.8669.hdf5\n",
            "Epoch 10/50\n",
            "135999/135999 [==============================] - 285s 2ms/step - loss: 1.8304\n",
            "\n",
            "Epoch 00010: loss improved from 1.86694 to 1.83037, saving model to /content/drive/My Drive/EIP/LSTM_weights-10-1.8304.hdf5\n",
            "Epoch 11/50\n",
            "135999/135999 [==============================] - 286s 2ms/step - loss: 1.8021\n",
            "\n",
            "Epoch 00011: loss improved from 1.83037 to 1.80208, saving model to /content/drive/My Drive/EIP/LSTM_weights-11-1.8021.hdf5\n",
            "Epoch 12/50\n",
            "135999/135999 [==============================] - 286s 2ms/step - loss: 1.7749\n",
            "\n",
            "Epoch 00012: loss improved from 1.80208 to 1.77487, saving model to /content/drive/My Drive/EIP/LSTM_weights-12-1.7749.hdf5\n",
            "Epoch 13/50\n",
            "135999/135999 [==============================] - 289s 2ms/step - loss: 1.7496\n",
            "\n",
            "Epoch 00013: loss improved from 1.77487 to 1.74962, saving model to /content/drive/My Drive/EIP/LSTM_weights-13-1.7496.hdf5\n",
            "Epoch 14/50\n",
            "135999/135999 [==============================] - 290s 2ms/step - loss: 1.7312\n",
            "\n",
            "Epoch 00014: loss improved from 1.74962 to 1.73123, saving model to /content/drive/My Drive/EIP/LSTM_weights-14-1.7312.hdf5\n",
            "Epoch 15/50\n",
            "135999/135999 [==============================] - 290s 2ms/step - loss: 1.7123\n",
            "\n",
            "Epoch 00015: loss improved from 1.73123 to 1.71225, saving model to /content/drive/My Drive/EIP/LSTM_weights-15-1.7123.hdf5\n",
            "Epoch 16/50\n",
            "135999/135999 [==============================] - 289s 2ms/step - loss: 1.6952\n",
            "\n",
            "Epoch 00016: loss improved from 1.71225 to 1.69522, saving model to /content/drive/My Drive/EIP/LSTM_weights-16-1.6952.hdf5\n",
            "Epoch 17/50\n",
            "135999/135999 [==============================] - 289s 2ms/step - loss: 1.6749\n",
            "\n",
            "Epoch 00017: loss improved from 1.69522 to 1.67486, saving model to /content/drive/My Drive/EIP/LSTM_weights-17-1.6749.hdf5\n",
            "Epoch 18/50\n",
            "135999/135999 [==============================] - 290s 2ms/step - loss: 1.6630\n",
            "\n",
            "Epoch 00018: loss improved from 1.67486 to 1.66299, saving model to /content/drive/My Drive/EIP/LSTM_weights-18-1.6630.hdf5\n",
            "Epoch 19/50\n",
            "135999/135999 [==============================] - 290s 2ms/step - loss: 1.6448\n",
            "\n",
            "Epoch 00019: loss improved from 1.66299 to 1.64475, saving model to /content/drive/My Drive/EIP/LSTM_weights-19-1.6448.hdf5\n",
            "Epoch 20/50\n",
            "135999/135999 [==============================] - 288s 2ms/step - loss: 1.6320\n",
            "\n",
            "Epoch 00020: loss improved from 1.64475 to 1.63201, saving model to /content/drive/My Drive/EIP/LSTM_weights-20-1.6320.hdf5\n",
            "Epoch 21/50\n",
            "135999/135999 [==============================] - 288s 2ms/step - loss: 1.6186\n",
            "\n",
            "Epoch 00021: loss improved from 1.63201 to 1.61864, saving model to /content/drive/My Drive/EIP/LSTM_weights-21-1.6186.hdf5\n",
            "Epoch 22/50\n",
            "135999/135999 [==============================] - 290s 2ms/step - loss: 1.6052\n",
            "\n",
            "Epoch 00022: loss improved from 1.61864 to 1.60525, saving model to /content/drive/My Drive/EIP/LSTM_weights-22-1.6052.hdf5\n",
            "Epoch 23/50\n",
            "135999/135999 [==============================] - 290s 2ms/step - loss: 1.5938\n",
            "\n",
            "Epoch 00023: loss improved from 1.60525 to 1.59380, saving model to /content/drive/My Drive/EIP/LSTM_weights-23-1.5938.hdf5\n",
            "Epoch 24/50\n",
            "135999/135999 [==============================] - 285s 2ms/step - loss: 1.5799\n",
            "\n",
            "Epoch 00024: loss improved from 1.59380 to 1.57990, saving model to /content/drive/My Drive/EIP/LSTM_weights-24-1.5799.hdf5\n",
            "Epoch 25/50\n",
            "135999/135999 [==============================] - 281s 2ms/step - loss: 1.5728\n",
            "\n",
            "Epoch 00025: loss improved from 1.57990 to 1.57281, saving model to /content/drive/My Drive/EIP/LSTM_weights-25-1.5728.hdf5\n",
            "Epoch 26/50\n",
            "135999/135999 [==============================] - 279s 2ms/step - loss: 1.5623\n",
            "\n",
            "Epoch 00026: loss improved from 1.57281 to 1.56227, saving model to /content/drive/My Drive/EIP/LSTM_weights-26-1.5623.hdf5\n",
            "Epoch 27/50\n",
            "135999/135999 [==============================] - 277s 2ms/step - loss: 1.5541\n",
            "\n",
            "Epoch 00027: loss improved from 1.56227 to 1.55406, saving model to /content/drive/My Drive/EIP/LSTM_weights-27-1.5541.hdf5\n",
            "Epoch 28/50\n",
            "135999/135999 [==============================] - 276s 2ms/step - loss: 1.5451\n",
            "\n",
            "Epoch 00028: loss improved from 1.55406 to 1.54515, saving model to /content/drive/My Drive/EIP/LSTM_weights-28-1.5451.hdf5\n",
            "Epoch 29/50\n",
            "135999/135999 [==============================] - 275s 2ms/step - loss: 1.5327\n",
            "\n",
            "Epoch 00029: loss improved from 1.54515 to 1.53275, saving model to /content/drive/My Drive/EIP/LSTM_weights-29-1.5327.hdf5\n",
            "Epoch 30/50\n",
            "135999/135999 [==============================] - 274s 2ms/step - loss: 1.5252\n",
            "\n",
            "Epoch 00030: loss improved from 1.53275 to 1.52519, saving model to /content/drive/My Drive/EIP/LSTM_weights-30-1.5252.hdf5\n",
            "Epoch 31/50\n",
            "135999/135999 [==============================] - 273s 2ms/step - loss: 1.5155\n",
            "\n",
            "Epoch 00031: loss improved from 1.52519 to 1.51554, saving model to /content/drive/My Drive/EIP/LSTM_weights-31-1.5155.hdf5\n",
            "Epoch 32/50\n",
            "135999/135999 [==============================] - 276s 2ms/step - loss: 1.5084\n",
            "\n",
            "Epoch 00032: loss improved from 1.51554 to 1.50835, saving model to /content/drive/My Drive/EIP/LSTM_weights-32-1.5084.hdf5\n",
            "Epoch 33/50\n",
            "135999/135999 [==============================] - 272s 2ms/step - loss: 1.4968\n",
            "\n",
            "Epoch 00033: loss improved from 1.50835 to 1.49682, saving model to /content/drive/My Drive/EIP/LSTM_weights-33-1.4968.hdf5\n",
            "Epoch 34/50\n",
            "135999/135999 [==============================] - 269s 2ms/step - loss: 1.4941\n",
            "\n",
            "Epoch 00034: loss improved from 1.49682 to 1.49408, saving model to /content/drive/My Drive/EIP/LSTM_weights-34-1.4941.hdf5\n",
            "Epoch 35/50\n",
            "135999/135999 [==============================] - 269s 2ms/step - loss: 1.4838\n",
            "\n",
            "Epoch 00035: loss improved from 1.49408 to 1.48377, saving model to /content/drive/My Drive/EIP/LSTM_weights-35-1.4838.hdf5\n",
            "Epoch 36/50\n",
            "135999/135999 [==============================] - 268s 2ms/step - loss: 1.4764\n",
            "\n",
            "Epoch 00036: loss improved from 1.48377 to 1.47636, saving model to /content/drive/My Drive/EIP/LSTM_weights-36-1.4764.hdf5\n",
            "Epoch 37/50\n",
            "135999/135999 [==============================] - 268s 2ms/step - loss: 1.4741\n",
            "\n",
            "Epoch 00037: loss improved from 1.47636 to 1.47413, saving model to /content/drive/My Drive/EIP/LSTM_weights-37-1.4741.hdf5\n",
            "Epoch 38/50\n",
            "135999/135999 [==============================] - 268s 2ms/step - loss: 1.4641\n",
            "\n",
            "Epoch 00038: loss improved from 1.47413 to 1.46412, saving model to /content/drive/My Drive/EIP/LSTM_weights-38-1.4641.hdf5\n",
            "Epoch 39/50\n",
            "135999/135999 [==============================] - 267s 2ms/step - loss: 1.4648\n",
            "\n",
            "Epoch 00039: loss did not improve from 1.46412\n",
            "Epoch 40/50\n",
            "135999/135999 [==============================] - 267s 2ms/step - loss: 1.4541\n",
            "\n",
            "Epoch 00040: loss improved from 1.46412 to 1.45406, saving model to /content/drive/My Drive/EIP/LSTM_weights-40-1.4541.hdf5\n",
            "Epoch 41/50\n",
            "135999/135999 [==============================] - 266s 2ms/step - loss: 1.4487\n",
            "\n",
            "Epoch 00041: loss improved from 1.45406 to 1.44870, saving model to /content/drive/My Drive/EIP/LSTM_weights-41-1.4487.hdf5\n",
            "Epoch 42/50\n",
            "135999/135999 [==============================] - 267s 2ms/step - loss: 1.4411\n",
            "\n",
            "Epoch 00042: loss improved from 1.44870 to 1.44113, saving model to /content/drive/My Drive/EIP/LSTM_weights-42-1.4411.hdf5\n",
            "Epoch 43/50\n",
            "135999/135999 [==============================] - 268s 2ms/step - loss: 1.4452\n",
            "\n",
            "Epoch 00043: loss did not improve from 1.44113\n",
            "Epoch 44/50\n",
            "135999/135999 [==============================] - 275s 2ms/step - loss: 1.4302\n",
            "\n",
            "Epoch 00044: loss improved from 1.44113 to 1.43021, saving model to /content/drive/My Drive/EIP/LSTM_weights-44-1.4302.hdf5\n",
            "Epoch 45/50\n",
            "135999/135999 [==============================] - 272s 2ms/step - loss: 1.4220\n",
            "\n",
            "Epoch 00045: loss improved from 1.43021 to 1.42196, saving model to /content/drive/My Drive/EIP/LSTM_weights-45-1.4220.hdf5\n",
            "Epoch 46/50\n",
            "135999/135999 [==============================] - 287s 2ms/step - loss: 1.4214\n",
            "\n",
            "Epoch 00046: loss improved from 1.42196 to 1.42144, saving model to /content/drive/My Drive/EIP/LSTM_weights-46-1.4214.hdf5\n",
            "Epoch 47/50\n",
            "135999/135999 [==============================] - 275s 2ms/step - loss: 1.4175\n",
            "\n",
            "Epoch 00047: loss improved from 1.42144 to 1.41745, saving model to /content/drive/My Drive/EIP/LSTM_weights-47-1.4175.hdf5\n",
            "Epoch 48/50\n",
            "135999/135999 [==============================] - 281s 2ms/step - loss: 1.4109\n",
            "\n",
            "Epoch 00048: loss improved from 1.41745 to 1.41093, saving model to /content/drive/My Drive/EIP/LSTM_weights-48-1.4109.hdf5\n",
            "Epoch 49/50\n",
            "135999/135999 [==============================] - 278s 2ms/step - loss: 1.4055\n",
            "\n",
            "Epoch 00049: loss improved from 1.41093 to 1.40548, saving model to /content/drive/My Drive/EIP/LSTM_weights-49-1.4055.hdf5\n",
            "Epoch 50/50\n",
            "135999/135999 [==============================] - 276s 2ms/step - loss: 1.3988\n",
            "\n",
            "Epoch 00050: loss improved from 1.40548 to 1.39880, saving model to /content/drive/My Drive/EIP/LSTM_weights-50-1.3988.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86dfa9f0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIXa2brw3QM0",
        "colab_type": "text"
      },
      "source": [
        "### continuing training after 50th epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqlFQVedZ4ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/drive/My Drive/EIP/LSTM_weights-50-1.3988.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp51dQypbaNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e9f7ed5-0c67-4488-b529-a1631e2e05b4"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "135999/135999 [==============================] - 286s 2ms/step - loss: 1.0921\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.09206, saving model to /content/drive/My Drive/EIP/LSTM_weights-01-1.0921.hdf5\n",
            "Epoch 2/20\n",
            "135999/135999 [==============================] - 286s 2ms/step - loss: 1.0544\n",
            "\n",
            "Epoch 00002: loss improved from 1.09206 to 1.05436, saving model to /content/drive/My Drive/EIP/LSTM_weights-02-1.0544.hdf5\n",
            "Epoch 3/20\n",
            "135999/135999 [==============================] - 288s 2ms/step - loss: 1.0275\n",
            "\n",
            "Epoch 00003: loss improved from 1.05436 to 1.02754, saving model to /content/drive/My Drive/EIP/LSTM_weights-03-1.0275.hdf5\n",
            "Epoch 4/20\n",
            "135999/135999 [==============================] - 286s 2ms/step - loss: 1.0040\n",
            "\n",
            "Epoch 00004: loss improved from 1.02754 to 1.00404, saving model to /content/drive/My Drive/EIP/LSTM_weights-04-1.0040.hdf5\n",
            "Epoch 5/20\n",
            "135999/135999 [==============================] - 287s 2ms/step - loss: 0.9845\n",
            "\n",
            "Epoch 00005: loss improved from 1.00404 to 0.98454, saving model to /content/drive/My Drive/EIP/LSTM_weights-05-0.9845.hdf5\n",
            "Epoch 6/20\n",
            "135999/135999 [==============================] - 283s 2ms/step - loss: 0.9654\n",
            "\n",
            "Epoch 00006: loss improved from 0.98454 to 0.96537, saving model to /content/drive/My Drive/EIP/LSTM_weights-06-0.9654.hdf5\n",
            "Epoch 7/20\n",
            "135999/135999 [==============================] - 285s 2ms/step - loss: 0.9475\n",
            "\n",
            "Epoch 00007: loss improved from 0.96537 to 0.94748, saving model to /content/drive/My Drive/EIP/LSTM_weights-07-0.9475.hdf5\n",
            "Epoch 8/20\n",
            "135999/135999 [==============================] - 284s 2ms/step - loss: 0.9297\n",
            "\n",
            "Epoch 00008: loss improved from 0.94748 to 0.92966, saving model to /content/drive/My Drive/EIP/LSTM_weights-08-0.9297.hdf5\n",
            "Epoch 9/20\n",
            "135999/135999 [==============================] - 285s 2ms/step - loss: 0.9152\n",
            "\n",
            "Epoch 00009: loss improved from 0.92966 to 0.91517, saving model to /content/drive/My Drive/EIP/LSTM_weights-09-0.9152.hdf5\n",
            "Epoch 10/20\n",
            "135999/135999 [==============================] - 283s 2ms/step - loss: 0.8987\n",
            "\n",
            "Epoch 00010: loss improved from 0.91517 to 0.89869, saving model to /content/drive/My Drive/EIP/LSTM_weights-10-0.8987.hdf5\n",
            "Epoch 11/20\n",
            "135999/135999 [==============================] - 282s 2ms/step - loss: 0.8867\n",
            "\n",
            "Epoch 00011: loss improved from 0.89869 to 0.88671, saving model to /content/drive/My Drive/EIP/LSTM_weights-11-0.8867.hdf5\n",
            "Epoch 12/20\n",
            "135999/135999 [==============================] - 283s 2ms/step - loss: 0.8707\n",
            "\n",
            "Epoch 00012: loss improved from 0.88671 to 0.87072, saving model to /content/drive/My Drive/EIP/LSTM_weights-12-0.8707.hdf5\n",
            "Epoch 13/20\n",
            "135999/135999 [==============================] - 280s 2ms/step - loss: 0.8569\n",
            "\n",
            "Epoch 00013: loss improved from 0.87072 to 0.85694, saving model to /content/drive/My Drive/EIP/LSTM_weights-13-0.8569.hdf5\n",
            "Epoch 14/20\n",
            "135999/135999 [==============================] - 285s 2ms/step - loss: 0.8450\n",
            "\n",
            "Epoch 00014: loss improved from 0.85694 to 0.84498, saving model to /content/drive/My Drive/EIP/LSTM_weights-14-0.8450.hdf5\n",
            "Epoch 15/20\n",
            "135999/135999 [==============================] - 285s 2ms/step - loss: 0.8325\n",
            "\n",
            "Epoch 00015: loss improved from 0.84498 to 0.83252, saving model to /content/drive/My Drive/EIP/LSTM_weights-15-0.8325.hdf5\n",
            "Epoch 16/20\n",
            "135999/135999 [==============================] - 287s 2ms/step - loss: 0.8275\n",
            "\n",
            "Epoch 00016: loss improved from 0.83252 to 0.82750, saving model to /content/drive/My Drive/EIP/LSTM_weights-16-0.8275.hdf5\n",
            "Epoch 17/20\n",
            "135999/135999 [==============================] - 289s 2ms/step - loss: 0.8095\n",
            "\n",
            "Epoch 00017: loss improved from 0.82750 to 0.80949, saving model to /content/drive/My Drive/EIP/LSTM_weights-17-0.8095.hdf5\n",
            "Epoch 18/20\n",
            "135999/135999 [==============================] - 287s 2ms/step - loss: 0.7991\n",
            "\n",
            "Epoch 00018: loss improved from 0.80949 to 0.79910, saving model to /content/drive/My Drive/EIP/LSTM_weights-18-0.7991.hdf5\n",
            "Epoch 19/20\n",
            "135999/135999 [==============================] - 284s 2ms/step - loss: 0.7900\n",
            "\n",
            "Epoch 00019: loss improved from 0.79910 to 0.79001, saving model to /content/drive/My Drive/EIP/LSTM_weights-19-0.7900.hdf5\n",
            "Epoch 20/20\n",
            "135999/135999 [==============================] - 284s 2ms/step - loss: 0.7831\n",
            "\n",
            "Epoch 00020: loss improved from 0.79001 to 0.78309, saving model to /content/drive/My Drive/EIP/LSTM_weights-20-0.7831.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f015e76fba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqmJNhH73ZBo",
        "colab_type": "text"
      },
      "source": [
        "### continuing training after 70th epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE_Pv1LC1CDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/drive/My Drive/EIP/LSTM_weights-20-0.7831.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os4SAsiG2uW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71d3b483-3a20-4282-825d-98bc5ac4a5c3"
      },
      "source": [
        "model.fit(X, y, epochs=30, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 09:56:15.444358 140480920938368 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "135999/135999 [==============================] - 397s 3ms/step - loss: 0.7764\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.77643, saving model to /content/drive/My Drive/EIP/LSTM_weights-01-0.7764.hdf5\n",
            "Epoch 2/30\n",
            "135999/135999 [==============================] - 401s 3ms/step - loss: 0.7625\n",
            "\n",
            "Epoch 00002: loss improved from 0.77643 to 0.76252, saving model to /content/drive/My Drive/EIP/LSTM_weights-02-0.7625.hdf5\n",
            "Epoch 3/30\n",
            "135999/135999 [==============================] - 401s 3ms/step - loss: 0.7545\n",
            "\n",
            "Epoch 00003: loss improved from 0.76252 to 0.75447, saving model to /content/drive/My Drive/EIP/LSTM_weights-03-0.7545.hdf5\n",
            "Epoch 4/30\n",
            "135999/135999 [==============================] - 403s 3ms/step - loss: 0.7457\n",
            "\n",
            "Epoch 00004: loss improved from 0.75447 to 0.74570, saving model to /content/drive/My Drive/EIP/LSTM_weights-04-0.7457.hdf5\n",
            "Epoch 5/30\n",
            "135999/135999 [==============================] - 404s 3ms/step - loss: 0.7397\n",
            "\n",
            "Epoch 00005: loss improved from 0.74570 to 0.73968, saving model to /content/drive/My Drive/EIP/LSTM_weights-05-0.7397.hdf5\n",
            "Epoch 6/30\n",
            "135999/135999 [==============================] - 397s 3ms/step - loss: 0.7334\n",
            "\n",
            "Epoch 00006: loss improved from 0.73968 to 0.73342, saving model to /content/drive/My Drive/EIP/LSTM_weights-06-0.7334.hdf5\n",
            "Epoch 7/30\n",
            "135999/135999 [==============================] - 396s 3ms/step - loss: 0.7230\n",
            "\n",
            "Epoch 00007: loss improved from 0.73342 to 0.72300, saving model to /content/drive/My Drive/EIP/LSTM_weights-07-0.7230.hdf5\n",
            "Epoch 8/30\n",
            "135999/135999 [==============================] - 396s 3ms/step - loss: 0.7202\n",
            "\n",
            "Epoch 00008: loss improved from 0.72300 to 0.72022, saving model to /content/drive/My Drive/EIP/LSTM_weights-08-0.7202.hdf5\n",
            "Epoch 9/30\n",
            "135999/135999 [==============================] - 402s 3ms/step - loss: 0.7089\n",
            "\n",
            "Epoch 00009: loss improved from 0.72022 to 0.70887, saving model to /content/drive/My Drive/EIP/LSTM_weights-09-0.7089.hdf5\n",
            "Epoch 10/30\n",
            "135999/135999 [==============================] - 403s 3ms/step - loss: 0.7033\n",
            "\n",
            "Epoch 00010: loss improved from 0.70887 to 0.70331, saving model to /content/drive/My Drive/EIP/LSTM_weights-10-0.7033.hdf5\n",
            "Epoch 11/30\n",
            "135999/135999 [==============================] - 401s 3ms/step - loss: 0.6982\n",
            "\n",
            "Epoch 00011: loss improved from 0.70331 to 0.69822, saving model to /content/drive/My Drive/EIP/LSTM_weights-11-0.6982.hdf5\n",
            "Epoch 12/30\n",
            "135999/135999 [==============================] - 405s 3ms/step - loss: 0.6949\n",
            "\n",
            "Epoch 00012: loss improved from 0.69822 to 0.69485, saving model to /content/drive/My Drive/EIP/LSTM_weights-12-0.6949.hdf5\n",
            "Epoch 13/30\n",
            "135999/135999 [==============================] - 399s 3ms/step - loss: 0.6895\n",
            "\n",
            "Epoch 00013: loss improved from 0.69485 to 0.68953, saving model to /content/drive/My Drive/EIP/LSTM_weights-13-0.6895.hdf5\n",
            "Epoch 14/30\n",
            "135999/135999 [==============================] - 404s 3ms/step - loss: 0.6782\n",
            "\n",
            "Epoch 00014: loss improved from 0.68953 to 0.67822, saving model to /content/drive/My Drive/EIP/LSTM_weights-14-0.6782.hdf5\n",
            "Epoch 15/30\n",
            "135999/135999 [==============================] - 408s 3ms/step - loss: 0.6765\n",
            "\n",
            "Epoch 00015: loss improved from 0.67822 to 0.67648, saving model to /content/drive/My Drive/EIP/LSTM_weights-15-0.6765.hdf5\n",
            "Epoch 16/30\n",
            "135999/135999 [==============================] - 410s 3ms/step - loss: 0.7860\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.67648\n",
            "Epoch 17/30\n",
            "135999/135999 [==============================] - 408s 3ms/step - loss: 0.6569\n",
            "\n",
            "Epoch 00017: loss improved from 0.67648 to 0.65686, saving model to /content/drive/My Drive/EIP/LSTM_weights-17-0.6569.hdf5\n",
            "Epoch 18/30\n",
            "135999/135999 [==============================] - 409s 3ms/step - loss: 0.6528\n",
            "\n",
            "Epoch 00018: loss improved from 0.65686 to 0.65280, saving model to /content/drive/My Drive/EIP/LSTM_weights-18-0.6528.hdf5\n",
            "Epoch 19/30\n",
            "135999/135999 [==============================] - 408s 3ms/step - loss: 0.6547\n",
            "\n",
            "Epoch 00019: loss did not improve from 0.65280\n",
            "Epoch 20/30\n",
            "135999/135999 [==============================] - 410s 3ms/step - loss: 0.6561\n",
            "\n",
            "Epoch 00020: loss did not improve from 0.65280\n",
            "Epoch 21/30\n",
            "135999/135999 [==============================] - 409s 3ms/step - loss: 0.6473\n",
            "\n",
            "Epoch 00021: loss improved from 0.65280 to 0.64732, saving model to /content/drive/My Drive/EIP/LSTM_weights-21-0.6473.hdf5\n",
            "Epoch 22/30\n",
            "135999/135999 [==============================] - 410s 3ms/step - loss: 0.6496\n",
            "\n",
            "Epoch 00022: loss did not improve from 0.64732\n",
            "Epoch 23/30\n",
            "135999/135999 [==============================] - 405s 3ms/step - loss: 0.6505\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.64732\n",
            "Epoch 24/30\n",
            "135999/135999 [==============================] - 408s 3ms/step - loss: 0.6334\n",
            "\n",
            "Epoch 00024: loss improved from 0.64732 to 0.63342, saving model to /content/drive/My Drive/EIP/LSTM_weights-24-0.6334.hdf5\n",
            "Epoch 25/30\n",
            "135999/135999 [==============================] - 402s 3ms/step - loss: 0.6305\n",
            "\n",
            "Epoch 00025: loss improved from 0.63342 to 0.63045, saving model to /content/drive/My Drive/EIP/LSTM_weights-25-0.6305.hdf5\n",
            "Epoch 26/30\n",
            "135999/135999 [==============================] - 403s 3ms/step - loss: 0.6369\n",
            "\n",
            "Epoch 00026: loss did not improve from 0.63045\n",
            "Epoch 27/30\n",
            "135999/135999 [==============================] - 408s 3ms/step - loss: 0.6254\n",
            "\n",
            "Epoch 00027: loss improved from 0.63045 to 0.62539, saving model to /content/drive/My Drive/EIP/LSTM_weights-27-0.6254.hdf5\n",
            "Epoch 28/30\n",
            "135999/135999 [==============================] - 405s 3ms/step - loss: 0.6479\n",
            "\n",
            "Epoch 00028: loss did not improve from 0.62539\n",
            "Epoch 29/30\n",
            "135999/135999 [==============================] - 408s 3ms/step - loss: 0.6142\n",
            "\n",
            "Epoch 00029: loss improved from 0.62539 to 0.61421, saving model to /content/drive/My Drive/EIP/LSTM_weights-29-0.6142.hdf5\n",
            "Epoch 30/30\n",
            "135999/135999 [==============================] - 406s 3ms/step - loss: 0.6084\n",
            "\n",
            "Epoch 00030: loss improved from 0.61421 to 0.60845, saving model to /content/drive/My Drive/EIP/LSTM_weights-30-0.6084.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc3f043eef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsE45mJ22dqK",
        "colab_type": "text"
      },
      "source": [
        "## Generating text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqKZFMdJ9Bbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/drive/My Drive/EIP/LSTM_weights-30-0.6084.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcsNyheq22hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i+1, c) for i, c in enumerate(chars))\n",
        "int_to_char[0]=''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FO11Tmu0PS_",
        "colab_type": "code",
        "outputId": "18e62acd-2ca5-4149-ecba-b2e78fbdae6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(paddedX)-1)\n",
        "\n",
        "# pad the seed\n",
        "pattern = paddedX[start]\n",
        "pattern = pattern.tolist()\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" he came trotting along in a great\n",
            "hurry muttering to himself as he came oh the duchess the duch \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEYbViYC2mGK",
        "colab_type": "code",
        "outputId": "d306bcb3-c878-4ecd-abe9-296954e9db78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ess said in a low trembling voice what thought alice as if she went on what he said alice and how fotm the things being all their simple jobsser and she tried to say \n",
            "to be no chance of the sort\n",
            "of little tolscker and the moral of that istt take little tors of his that she was beginning to her feet for a farher she shouting off with his head off and the loral of that is the cat went on the rabbit and said nothing\n",
            "\n",
            "when we were little the moment said the mock turtle and the moral of that istt the\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9USDlQZ630X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}